{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4t/55hr34s50pb0bz56v_nxv0j00000gn/T/ipykernel_25014/1987216083.py:17: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import Image, display\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from torchsummary import summary\n",
    "\n",
    "# from pushover import notify\n",
    "# from utils import makegif\n",
    "from random import randint\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import Image, display\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './rollouts'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Load Data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m dataset \u001b[39m=\u001b[39m datasets\u001b[39m.\u001b[39;49mImageFolder(root\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m./rollouts\u001b[39;49m\u001b[39m'\u001b[39;49m, transform\u001b[39m=\u001b[39;49mtransforms\u001b[39m.\u001b[39;49mCompose([\n\u001b[1;32m      3\u001b[0m     transforms\u001b[39m.\u001b[39;49mResize(\u001b[39m64\u001b[39;49m),\n\u001b[1;32m      4\u001b[0m     transforms\u001b[39m.\u001b[39;49mToTensor(), \n\u001b[1;32m      5\u001b[0m ]))\n\u001b[1;32m      6\u001b[0m dataloader \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataLoader(dataset, batch_size\u001b[39m=\u001b[39mbs, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      7\u001b[0m \u001b[39mlen\u001b[39m(dataset\u001b[39m.\u001b[39mimgs), \u001b[39mlen\u001b[39m(dataloader)\n",
      "File \u001b[0;32m~/miniforge3/envs/torch-gpu/lib/python3.8/site-packages/torchvision/datasets/folder.py:309\u001b[0m, in \u001b[0;36mImageFolder.__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[1;32m    302\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    303\u001b[0m     root: \u001b[39mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    307\u001b[0m     is_valid_file: Optional[Callable[[\u001b[39mstr\u001b[39m], \u001b[39mbool\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    308\u001b[0m ):\n\u001b[0;32m--> 309\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[1;32m    310\u001b[0m         root,\n\u001b[1;32m    311\u001b[0m         loader,\n\u001b[1;32m    312\u001b[0m         IMG_EXTENSIONS \u001b[39mif\u001b[39;49;00m is_valid_file \u001b[39mis\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    313\u001b[0m         transform\u001b[39m=\u001b[39;49mtransform,\n\u001b[1;32m    314\u001b[0m         target_transform\u001b[39m=\u001b[39;49mtarget_transform,\n\u001b[1;32m    315\u001b[0m         is_valid_file\u001b[39m=\u001b[39;49mis_valid_file,\n\u001b[1;32m    316\u001b[0m     )\n\u001b[1;32m    317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimgs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msamples\n",
      "File \u001b[0;32m~/miniforge3/envs/torch-gpu/lib/python3.8/site-packages/torchvision/datasets/folder.py:144\u001b[0m, in \u001b[0;36mDatasetFolder.__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[1;32m    135\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    136\u001b[0m     root: \u001b[39mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    141\u001b[0m     is_valid_file: Optional[Callable[[\u001b[39mstr\u001b[39m], \u001b[39mbool\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    142\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    143\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(root, transform\u001b[39m=\u001b[39mtransform, target_transform\u001b[39m=\u001b[39mtarget_transform)\n\u001b[0;32m--> 144\u001b[0m     classes, class_to_idx \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfind_classes(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mroot)\n\u001b[1;32m    145\u001b[0m     samples \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_dataset(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mroot, class_to_idx, extensions, is_valid_file)\n\u001b[1;32m    147\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloader \u001b[39m=\u001b[39m loader\n",
      "File \u001b[0;32m~/miniforge3/envs/torch-gpu/lib/python3.8/site-packages/torchvision/datasets/folder.py:218\u001b[0m, in \u001b[0;36mDatasetFolder.find_classes\u001b[0;34m(self, directory)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfind_classes\u001b[39m(\u001b[39mself\u001b[39m, directory: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[List[\u001b[39mstr\u001b[39m], Dict[\u001b[39mstr\u001b[39m, \u001b[39mint\u001b[39m]]:\n\u001b[1;32m    192\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Find the class folders in a dataset structured as follows::\u001b[39;00m\n\u001b[1;32m    193\u001b[0m \n\u001b[1;32m    194\u001b[0m \u001b[39m        directory/\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[39m        (Tuple[List[str], Dict[str, int]]): List of all classes and dictionary mapping each class to an index.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 218\u001b[0m     \u001b[39mreturn\u001b[39;00m find_classes(directory)\n",
      "File \u001b[0;32m~/miniforge3/envs/torch-gpu/lib/python3.8/site-packages/torchvision/datasets/folder.py:40\u001b[0m, in \u001b[0;36mfind_classes\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfind_classes\u001b[39m(directory: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[List[\u001b[39mstr\u001b[39m], Dict[\u001b[39mstr\u001b[39m, \u001b[39mint\u001b[39m]]:\n\u001b[1;32m     36\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Finds the class folders in a dataset.\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \n\u001b[1;32m     38\u001b[0m \u001b[39m    See :class:`DatasetFolder` for details.\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m     classes \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(entry\u001b[39m.\u001b[39mname \u001b[39mfor\u001b[39;00m entry \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39;49mscandir(directory) \u001b[39mif\u001b[39;00m entry\u001b[39m.\u001b[39mis_dir())\n\u001b[1;32m     41\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m classes:\n\u001b[1;32m     42\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCouldn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt find any class folder in \u001b[39m\u001b[39m{\u001b[39;00mdirectory\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './rollouts'"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "dataset = datasets.ImageFolder(root='./rollouts', transform=transforms.Compose([\n",
    "    transforms.Resize(64),\n",
    "    transforms.ToTensor(), \n",
    "]))\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=bs, shuffle=True)\n",
    "len(dataset.imgs), len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Fixed input for debugging\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m fixed_x, _ \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\u001b[39miter\u001b[39m(dataloader))\n\u001b[1;32m      3\u001b[0m save_image(fixed_x, \u001b[39m'\u001b[39m\u001b[39mreal_image.png\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m Image(\u001b[39m'\u001b[39m\u001b[39mreal_image.png\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataloader' is not defined"
     ]
    }
   ],
   "source": [
    "# Fixed input for debugging\n",
    "fixed_x, _ = next(iter(dataloader))\n",
    "save_image(fixed_x, 'real_image.png')\n",
    "\n",
    "Image('real_image.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnFlatten(nn.Module):\n",
    "    def forward(self, input, size=1024):\n",
    "        return input.view(input.size(0), size, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintLayer(nn.Module):\n",
    "    def __init__(self, name=None):\n",
    "        super(PrintLayer, self).__init__()\n",
    "        self.name = name\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Do your print / debug stuff here\n",
    "        print(self.name)\n",
    "        # print(x)\n",
    "        print(x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, image_channels=3, h_dim=1024, z_dim=32):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            PrintLayer('input encoder'),\n",
    "            nn.Conv2d(image_channels, 32, kernel_size=4, stride=2),\n",
    "            PrintLayer('1'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
    "            PrintLayer('2'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=2),\n",
    "            PrintLayer('3'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 256, kernel_size=4, stride=2),\n",
    "            PrintLayer('4'),\n",
    "            nn.ReLU(),\n",
    "            Flatten(),\n",
    "            PrintLayer('Flatten'),\n",
    "        )\n",
    "        \n",
    "        self.fc1 = nn.Linear(h_dim, z_dim)\n",
    "        self.fc2 = nn.Linear(h_dim, z_dim)\n",
    "        self.fc3 = nn.Linear(z_dim, h_dim)\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            PrintLayer('input decocer'),\n",
    "            UnFlatten(),\n",
    "            PrintLayer('UnFlatten'),\n",
    "            nn.ConvTranspose2d(h_dim, 128, kernel_size=5, stride=2),\n",
    "            PrintLayer('5'),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=5, stride=2),\n",
    "            PrintLayer('6'),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=6, stride=2),\n",
    "            PrintLayer('7'),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, image_channels, kernel_size=6, stride=2),\n",
    "            PrintLayer('8'),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = logvar.mul(0.5).exp_()\n",
    "        # return torch.normal(mu, std)\n",
    "        esp = torch.randn(*mu.size())\n",
    "        z = mu + std * esp\n",
    "        return z\n",
    "    \n",
    "    def bottleneck(self, h):\n",
    "        mu, logvar = self.fc1(h), self.fc2(h)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return z, mu, logvar\n",
    "\n",
    "    def encode(self, x):\n",
    "        h = self.encoder(x)\n",
    "        z, mu, logvar = self.bottleneck(h)\n",
    "        return z, mu, logvar\n",
    "\n",
    "    def decode(self, z):\n",
    "        z = self.fc3(z)\n",
    "        z = self.decoder(z)\n",
    "        return z\n",
    "\n",
    "    def forward(self, x):\n",
    "        z, mu, logvar = self.encode(x)\n",
    "        z = self.decode(z)\n",
    "        return z, mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fixed_x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m image_channels \u001b[39m=\u001b[39m fixed_x\u001b[39m.\u001b[39msize(\u001b[39m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fixed_x' is not defined"
     ]
    }
   ],
   "source": [
    "image_channels = fixed_x.size(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input encoder\n",
      "torch.Size([2, 3, 64, 64])\n",
      "1\n",
      "torch.Size([2, 32, 31, 31])\n",
      "2\n",
      "torch.Size([2, 64, 14, 14])\n",
      "3\n",
      "torch.Size([2, 128, 6, 6])\n",
      "4\n",
      "torch.Size([2, 256, 2, 2])\n",
      "Flatten\n",
      "torch.Size([2, 1024])\n",
      "input decocer\n",
      "torch.Size([2, 1024])\n",
      "UnFlatten\n",
      "torch.Size([2, 1024, 1, 1])\n",
      "5\n",
      "torch.Size([2, 128, 5, 5])\n",
      "6\n",
      "torch.Size([2, 64, 13, 13])\n",
      "7\n",
      "torch.Size([2, 32, 30, 30])\n",
      "8\n",
      "torch.Size([2, 3, 64, 64])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "        PrintLayer-1            [-1, 3, 64, 64]               0\n",
      "            Conv2d-2           [-1, 32, 31, 31]           1,568\n",
      "        PrintLayer-3           [-1, 32, 31, 31]               0\n",
      "              ReLU-4           [-1, 32, 31, 31]               0\n",
      "            Conv2d-5           [-1, 64, 14, 14]          32,832\n",
      "        PrintLayer-6           [-1, 64, 14, 14]               0\n",
      "              ReLU-7           [-1, 64, 14, 14]               0\n",
      "            Conv2d-8            [-1, 128, 6, 6]         131,200\n",
      "        PrintLayer-9            [-1, 128, 6, 6]               0\n",
      "             ReLU-10            [-1, 128, 6, 6]               0\n",
      "           Conv2d-11            [-1, 256, 2, 2]         524,544\n",
      "       PrintLayer-12            [-1, 256, 2, 2]               0\n",
      "             ReLU-13            [-1, 256, 2, 2]               0\n",
      "          Flatten-14                 [-1, 1024]               0\n",
      "       PrintLayer-15                 [-1, 1024]               0\n",
      "           Linear-16                   [-1, 32]          32,800\n",
      "           Linear-17                   [-1, 32]          32,800\n",
      "           Linear-18                 [-1, 1024]          33,792\n",
      "       PrintLayer-19                 [-1, 1024]               0\n",
      "        UnFlatten-20           [-1, 1024, 1, 1]               0\n",
      "       PrintLayer-21           [-1, 1024, 1, 1]               0\n",
      "  ConvTranspose2d-22            [-1, 128, 5, 5]       3,276,928\n",
      "       PrintLayer-23            [-1, 128, 5, 5]               0\n",
      "             ReLU-24            [-1, 128, 5, 5]               0\n",
      "  ConvTranspose2d-25           [-1, 64, 13, 13]         204,864\n",
      "       PrintLayer-26           [-1, 64, 13, 13]               0\n",
      "             ReLU-27           [-1, 64, 13, 13]               0\n",
      "  ConvTranspose2d-28           [-1, 32, 30, 30]          73,760\n",
      "       PrintLayer-29           [-1, 32, 30, 30]               0\n",
      "             ReLU-30           [-1, 32, 30, 30]               0\n",
      "  ConvTranspose2d-31            [-1, 3, 64, 64]           3,459\n",
      "       PrintLayer-32            [-1, 3, 64, 64]               0\n",
      "          Sigmoid-33            [-1, 3, 64, 64]               0\n",
      "================================================================\n",
      "Total params: 4,348,547\n",
      "Trainable params: 4,348,547\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.05\n",
      "Forward/backward pass size (MB): 2.52\n",
      "Params size (MB): 16.59\n",
      "Estimated Total Size (MB): 19.16\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = VAE(image_channels=3).to(device)\n",
    "summary(model, (3, 64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.load_state_dict(torch.load('vae.torch', map_location='cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vae' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(vae\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m1e-3\u001b[39m) \n",
      "\u001b[0;31mNameError\u001b[0m: name 'vae' is not defined"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(vae.parameters(), lr=1e-3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(recon_x, x, mu, logvar):\n",
    "    BCE = F.binary_cross_entropy(recon_x, x, size_average=False)\n",
    "    # BCE = F.mse_loss(recon_x, x, size_average=False)\n",
    "\n",
    "    # see Appendix B from VAE paper:\n",
    "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    KLD = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "    return BCE + KLD, BCE, KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rfr reconstructed\n",
    "!mkdir reconstructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for idx, (images, _) in enumerate(dataloader):\n",
    "        recon_images, mu, logvar = vae(images)\n",
    "        loss, bce, kld = loss_fn(recon_images, images, mu, logvar)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        to_print = \"Epoch[{}/{}] Loss: {:.3f} {:.3f} {:.3f}\".format(epoch+1, \n",
    "                                epochs, loss.data[0]/bs, bce.data[0]/bs, kld.data[0]/bs)\n",
    "        print(to_print)\n",
    "\n",
    "# notify to android when finished training\n",
    "notify(to_print, priority=1)\n",
    "\n",
    "torch.save(vae.state_dict(), 'vae.torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(x):\n",
    "    recon_x, _, _ = vae(x)\n",
    "    return torch.cat([x, recon_x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {
      "image/png": {
       "unconfined": true,
       "width": 700
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sample = torch.randn(bs, 1024)\n",
    "# compare_x = vae.decoder(sample)\n",
    "\n",
    "# fixed_x, _ = next(iter(dataloader))\n",
    "# fixed_x = fixed_x[:8]\n",
    "fixed_x = dataset[randint(1, 100)][0].unsqueeze(0)\n",
    "compare_x = compare(fixed_x)\n",
    "\n",
    "save_image(compare_x.data.cpu(), 'sample_image.png')\n",
    "display(Image('sample_image.png', width=700, unconfined=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
